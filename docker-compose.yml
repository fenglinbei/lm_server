version: '3.10'

services:
  llm_api_server:
    container_name: llm_server
    build: ./docker/
    command: bash run.sh
    ulimits:
      stack: 67108864
      memlock: -1
    volumes:
      - $PWD:/workspace
      - /root/model/:/workspace/checkpoints/
    env_file:
      - .env
    network_mode: "host"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-sS", "http://localhost:5005/v1/models"]
      interval: 10s
      timeout: 10s
      retries: 6